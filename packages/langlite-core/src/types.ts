/**
 * Configuration options for initializing the Langlite SDK client.
 */
export interface LangliteConfig {
  /**
   * The public API key for identifying your project (optional).
   */
  publicKey?: string;
  /**
   * The secret API key for authenticating requests to Langlite.
   */
  secretKey: string;
  /**
   * The base URL of the Langlite API (optional, defaults to the Langlite cloud).
   */
  host?: string;
  /**
   * How often (in milliseconds) the SDK should flush (send) traces to the server.
   * If omitted, the default flush interval is used.
   */
  flushInterval?: number;
  /**
   * Configuration options for retry behavior when exports fail.
   */
  retryConfig?: {
    /**
     * Maximum number of retry attempts for failed exports (default: 5).
     */
    maxRetries?: number;
    /**
     * Base backoff time in milliseconds for exponential backoff (default: 1000).
     */
    baseBackoffMs?: number;
    /**
     * Maximum backoff time in milliseconds (default: 30000).
     */
    maxBackoffMs?: number;
    /**
     * Number of batch retry attempts before falling back to individual retries (default: 1).
     */
    batchRetryAttempts?: number;
    /**
     * Delay in milliseconds between batch retry attempts (default: 2000).
     */
    batchRetryDelayMs?: number;
  };
}

/**
 * Arguments for starting a new trace.
 */
export interface TraceArgs {
  /**
   * The name of the trace (e.g., operation or request identifier).
   */
  name: string;
  /**
   * Optional metadata associated with the trace.
   * Can be any key-value pairs relevant to your application.
   */
  metadata?: Record<string, unknown>;
}

/**
 * Arguments for adding a generation to a trace.
 * A generation typically represents a model output (e.g., LLM response).
 */
export interface GenerationArgs {
  /**
   * The name of this generation (e.g., operation name or step identifier).
   */
  name: string;
  /**
   * The input provided to the model for this generation.
   */
  input: string;
  /**
   * The output generated by the model.
   */
  output: string;
  /**
   * The name or identifier of the model used (e.g., "gpt-4", "gpt-3.5-turbo").
   */
  model: string;
  /**
   * Optional usage statistics, such as token counts.
   * Keys can include "promptTokens", "completionTokens", or any other numeric metrics.
   */
  usage?: {
    promptTokens?: number;
    completionTokens?: number;
    [key: string]: number | undefined;
  };
  /**
   * Optional metadata associated with this generation.
   */
  metadata?: Record<string, unknown>;
}

/**
 * Arguments for adding a span to a trace.
 * A span typically represents a timed operation or sub-task within a trace.
 */
export interface SpanArgs {
  /**
   * The name of the span (e.g., "db-query", "api-call").
   */
  name: string;
  /**
   * The start time of the span, as a Unix timestamp.
   * If omitted, the current time is used.
   */
  startTime?: number;
  /**
   * The end time of the span, as a Unix timestamp.
   * If omitted, the span is considered ongoing until finished explicitly.
   */
  endTime?: number;
  /**
   * Optional metadata associated with the span.
   */
  metadata?: Record<string, unknown>;
}

/**
 * Arguments for logging an event within a trace.
 */
export interface EventArgs {
  /**
   * The message describing the event.
   */
  message: string;
  /**
   * The time the event occurred, as a Unix timestamp.
   * If omitted, the current time is used.
   */
  timestamp?: number;
  /**
   * Optional metadata associated with the event.
   */
  metadata?: Record<string, unknown>;
}

/**
 * Arguments for submitting a score to a trace or generation.
 * A score typically represents human or automated evaluation.
 */
export interface ScoreArgs {
  /**
   * The value of the score (e.g., 1 for positive, 0 for negative, or any numeric scale).
   */
  value: number;
  /**
   * Optional reason or explanation for the score.
   */
  reason?: string;
  /**
   * Optional metadata associated with the score.
   */
  metadata?: Record<string, unknown>;
}
